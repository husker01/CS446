# -*- coding: utf-8 -*-
"""Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/176Xf2uiHw-0YcxoxcisNO6uKVj2HiJt9
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Define dataset transform
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Load MNIST dataset
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)

# Set batch size
batch_size = 128

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)

# Define encoder architecture
class Encoder(nn.Module):
    def __init__(self, Dz=2):
        super().__init__()
        self.fc1 = nn.Linear(784, 500)
        self.fc2 = nn.Linear(500, 500)
        self.fc31 = nn.Linear(500, Dz)
        self.fc32 = nn.Linear(500, Dz)
        self.tanh = nn.Tanh()

    def forward(self, x):
        x = x.view(-1, 784)
        x = self.fc1(x)
        x = self.tanh(x)
        x = self.fc2(x)
        x = self.tanh(x)
        mu = self.fc31(x)
        logvar = self.fc32(x)
        return mu, logvar

# Define decoder architecture
class Decoder(nn.Module):
    def __init__(self, Dz=2):
        super().__init__()
        self.fc1 = nn.Linear(Dz, 500)
        self.fc2 = nn.Linear(500, 500)
        self.fc3 = nn.Linear(500, 784)
        self.tanh = nn.Tanh()
        self.sigmoid = nn.Sigmoid()

    def forward(self, z):
        x = self.fc1(z)
        x = self.tanh(x)
        x = self.fc2(x)
        x = self.tanh(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

# Define VAE model
class VAE(nn.Module):
    def __init__(self, Dz=2):
        super().__init__()
        self.encoder = Encoder(Dz)
        self.decoder = Decoder(Dz)

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        z = mu + eps * std
        return z

    def forward(self, x):
        mu, logvar = self.encoder(x)
        z = self.reparameterize(mu, logvar)
        x_recon = self.decoder(z)
        return x_recon, mu, logvar

    def loss_function(self, x_recon, x, mu, logvar):
        BCE = nn.functional.binary_cross_entropy(x_recon, x.view(-1, 784), reduction='sum')
        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
        return BCE + KLD

# Set random seed
torch.manual_seed(42)

# Initialize model and optimizer
vae = VAE().to(device)
optimizer = optim.Adam(vae.parameters(), lr=0.001)

"""#(B) Distribution"""

def logpdf_diagonal_gaussian(z, mu, logvar):
    # Computes log pdf of diagonal gaussian distribution
    c = - 0.5 * np.log(2 * np.pi)
    return torch.sum(c - logvar/2. - (z - mu)**2 / (2 * torch.exp(logvar)), dim=1)

def logpdf_bernoulli(x, p):
    # Computes log pdf of bernoulli distribution
    return torch.sum(x * torch.log(p) + (1 - x) * torch.log(1 - p), dim=1)

def sample_diagonal_gaussian(mu, logvar):
    # Sample from diagonal gaussian using reparameterization trick
    eps = torch.randn_like(logvar)
    return mu + torch.exp(logvar / 2) * eps

def sample_bernoulli(p):
    # Sample from bernoulli distribution
    return (torch.rand_like(p) < p).float()

"""#(c) Variational Objective"""

def elbo(x, recon_x, mu, logvar):
    # Computes the evidence lower bound (ELBO) given data and reconstruction
    logpx_given_z = logpdf_bernoulli(x, recon_x)
    logpz = logpdf_diagonal_gaussian(mu, torch.zeros_like(mu), torch.zeros_like(logvar))
    logqz_given_x = logpdf_diagonal_gaussian(mu, mu, logvar)
    return torch.mean(logpx_given_z + logpz - logqz_given_x)

"""#(d) Training"""

def train(model, dataloader, optimizer, num_epochs=10):
    # Train model for specified number of epochs
    for epoch in range(num_epochs):
        total_loss = 0
        for i, (x, _) in enumerate(dataloader):
            x = x.to(device)
            optimizer.zero_grad()
            recon_x, mu, logvar = model(x)
            loss = -elbo(x, recon_x, mu, logvar)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/(i+1):.4f}")

"""#Visualization"""

# Set number of epochs
num_epochs = 10

# Training loop
for epoch in range(num_epochs):
    train_loss = 0
    for batch_idx, (x, _) in enumerate(train_loader):
        # Move data to device
        x = x.to(device)

        # Forward pass
        x_recon, mu, logvar = vae(x)

        # Compute loss
        loss = vae.loss_function(x_recon, x, mu, logvar)

        # Backward pass and optimization step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()

        # Print progress
        if (batch_idx + 1) % 100 == 0:
            print('Epoch [{}/{}], Batch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, num_epochs, batch_idx+1, len(train_loader), train_loss / (batch_idx+1)))

    # Evaluate on test set
    test_loss = 0
    with torch.no_grad():
        for batch_idx, (x, _) in enumerate(test_loader):
            # Move data to device
            x = x.to(device)

            # Forward pass
            x_recon, mu, logvar = vae(x)

            # Compute loss
            loss = vae.loss_function(x_recon, x, mu, logvar)

            test_loss += loss.item()

    print('Epoch [{}/{}], Test Loss: {:.4f}'.format(epoch+1, num_epochs, test_loss / len(test_loader)))

# Generate some samples from the model
with torch.no_grad():
    z = torch.randn(64, 2).to(device)
    samples = vae.decoder(z).view(64, 1, 28, 28)
    torchvision.utils.save_image(samples, 'samples.png')

"""#Part 2"""

import matplotlib.pyplot as plt
import numpy as np

def visualize_latent_space(vae, data_loader):
    # Set the model to evaluation mode
    vae.eval()
    
    # Create empty lists to store the encoded features and labels
    features = []
    labels = []

    # Iterate through the data loader
    with torch.no_grad():
        for data, target in data_loader:
            data = data.to(device)
            target = target.to(device)
            
            # Encode the input image
            mu, logvar = vae.encoder(data)
            z = vae.reparameterize(mu, logvar)

            # Append the encoded features and labels to the lists
            features.append(z.cpu().numpy())
            labels.append(target.cpu().numpy())

    # Concatenate the encoded features and labels into a single array
    features = np.concatenate(features)
    labels = np.concatenate(labels)

    # Create a scatter plot of the latent space
    plt.figure(figsize=(10, 8))
    plt.scatter(features[:, 0], features[:, 1], c=labels, cmap='tab10', alpha=0.5)
    plt.colorbar()
    plt.xlabel('Latent Feature 1')
    plt.ylabel('Latent Feature 2')
    plt.title('Latent Space Visualization')
    plt.show()

class VAE(nn.Module):
    def __init__(self, latent_dim):
        super().__init__()

        # Define the encoder network
        self.encoder = nn.Sequential(
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, latent_dim * 2),  # fix shape mismatch here
        )

        # Define the decoder network
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 784),
            nn.Sigmoid(),
        )

    def encode(self, x):
        x = x.view(-1, 784)
        mu, logvar = torch.chunk(self.encoder(x), 2, dim=1)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z):
        return self.decoder(z).view(-1, 1, 28, 28)

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon_x = self.decode(z)
        return recon_x, mu, logvar

import torch
import numpy as np
import matplotlib.pyplot as plt

def visualize_latent_space(vae, train_loader):
    # Set the VAE to evaluation mode
    vae.eval()

    # Create empty lists to store the latent vectors and the class labels
    latent_vectors = []
    labels = []

    # Iterate over the training data and encode each image in the latent space
    with torch.no_grad():
        for data, label in train_loader:
            mu, _ = vae.encode(data)
            latent_vectors.append(mu)
            labels.append(label)

    # Concatenate the latent vectors and labels
    latent_vectors = torch.cat(latent_vectors, dim=0)
    labels = torch.cat(labels, dim=0)

    # Convert the latent vectors and labels to numpy arrays
    latent_vectors = latent_vectors.numpy()
    labels = labels.numpy()

    # Plot the latent vectors in 2D using a scatter plot
    plt.figure(figsize=(10, 10))
    plt.scatter(latent_vectors[:, 0], latent_vectors[:, 1], c=labels, cmap='tab10')
    plt.colorbar()

    # Set axis labels and title
    plt.xlabel('Latent dimension 1')
    plt.ylabel('Latent dimension 2')
    plt.title('Latent space visualization')

    # Show the plot
    plt.show()

# Train the VAE and create the data loader
# ...

# Visualize the latent space
visualize_latent_space(vae, train_loader)

"""#Just for testing """

import torch
import numpy as np
import matplotlib.pyplot as plt

def visualize_latent_space(vae, train_loader):
    # Set the VAE to evaluation mode
    vae.eval()

    # Create empty lists to store the latent vectors and the class labels
    latent_vectors = []
    labels = []

    # Iterate over the training data and encode each image in the latent space
    with torch.no_grad():
        for data, label in train_loader:
            mu, _ = vae.encode(data)
            latent_vectors.append(mu)
            labels.append(label)

    # Concatenate the latent vectors and labels
    latent_vectors = torch.cat(latent_vectors, dim=0)
    labels = torch.cat(labels, dim=0)

    # Convert the latent vectors and labels to numpy arrays
    latent_vectors = latent_vectors.numpy()
    labels = labels.numpy()

    # Plot the latent vectors in 2D using a scatter plot
    plt.figure(figsize=(10, 10))
    plt.scatter(latent_vectors[:, 0], latent_vectors[:, 1], c=labels, cmap='tab10')
    plt.colorbar()

    # Set axis labels and title
    plt.xlabel('Latent dimension 1')
    plt.ylabel('Latent dimension 2')
    plt.title('Latent space visualization')

    # Show the plot
    plt.show()

# Train the VAE and create the data loader
# ...

# Visualize the latent space
#visualize_latent_space(vae, train_loader)

"""#Part 3"""

import matplotlib.pyplot as plt

def visualize_inter_class_interpolation(self):
    # Sample 3 pairs of data points with different classes
    pairs = [(img1, label1, img2, label2) for (img1, label1), (img2, label2) in zip(self.train_images[:3], self.train_images[3:6])]
    
    # Encode the data in each pair and take the mean vectors
    mean_vectors = []
    for img1, label1, img2, label2 in pairs:
        _, mu1, _ = self.encoder.predict(img1)
        _, mu2, _ = self.encoder.predict(img2)
        mean_vectors.append((mu1, label1, mu2, label2))
    
    # Interpolate between the mean vectors
    alpha_values = [i/10 for i in range(11)]
    interpolated_vectors = []
    for i in range(len(mean_vectors)-1):
        for alpha in alpha_values:
            z_alpha = interpolate_mu(mean_vectors[i][0], mean_vectors[i+1][0], alpha)
            interpolated_vectors.append((z_alpha, mean_vectors[i][1], mean_vectors[i+1][1]))
    
    # Plot the distributions p(x|z_alpha) for each interpolated vector
    fig, axs = plt.subplots(nrows=11, ncols=1, figsize=(8, 16))
    for i, (z_alpha, label1, label2) in enumerate(interpolated_vectors):
        x = self.decoder.predict(z_alpha)
        axs[i].imshow(x.squeeze(), cmap='gray')
        axs[i].set_xticks([])
        axs[i].set_yticks([])
        axs[i].set_xlabel(f'{label1} (α={1-i/10:.1f}), {label2} (α={i/10:.1f})')
    
    # Concatenate the plots into one figure
    fig.tight_layout()
    fig.subplots_adjust(hspace=0.05)
    plt.show()

import matplotlib.pyplot as plt
import numpy as np

def visualize_inter_class_interpolation(self):
    # Sample 3 pairs of data points with different classes
    pairs = [(img1, label1, img2, label2) for (img1, label1), (img2, label2) in zip(self.train_images[:3], self.train_images[3:6])]
    
    # Encode the data in each pair and take the mean vectors
    mean_vectors = []
    for img1, label1, img2, label2 in pairs:
        _, mu1, _ = self.encoder.predict(img1)
        _, mu2, _ = self.encoder.predict(img2)
        mean_vectors.append((mu1, label1, mu2, label2))
    
    # Interpolate between the mean vectors
    alpha_values = [i/10 for i in range(11)]
    interpolated_vectors = []
    for i in range(len(mean_vectors)-1):
        for alpha in alpha_values:
            z_alpha = interpolate_mu(mean_vectors[i][0], mean_vectors[i+1][0], alpha)
            interpolated_vectors.append((z_alpha, mean_vectors[i][1], mean_vectors[i+1][1]))
    
    # Plot the distributions p(x|z_alpha) for each interpolated vector
    fig, axs = plt.subplots(nrows=11, ncols=1, figsize=(8, 16))
    for i, (z_alpha, label1, label2) in enumerate(interpolated_vectors):
        x = self.decoder.predict(np.array([z_alpha]))
        axs[i].imshow(x.squeeze(), cmap='gray')
        axs[i].set_xticks([])
        axs[i].set_yticks([])
        axs[i].set_xlabel(f'{label1} (α={1-i/10:.1f}), {label2} (α={i/10:.1f})')
    
    # Concatenate the plots into one figure
    fig.tight_layout()
    fig.subplots_adjust(hspace=0.05)
    
    # Save the figure to a file
    plt.savefig('interpolation.png')

import os
print(os.getcwd())

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torchvision.utils import make_grid, save_image
import numpy as np
import matplotlib.pyplot as plt



class MyModel(nn.Module):
    def __init__(self, latent_dim=20):
        super(MyModel, self).__init__()

        # Define encoder layers
        self.encoder = nn.Sequential(
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim * 2),
        )

        # Define decoder layers
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 784),
            nn.Sigmoid(),
        )

    def encode(self, x):
        # Flatten input tensor
        x = x.view(x.size(0), -1)

        # Pass through encoder
        x = self.encoder(x)

        # Split output into mean and variance components
        mu, logvar = torch.chunk(x, 2, dim=1)

        # Apply reparameterization trick to obtain sample
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        z = mu + eps * std

        return z, mu, logvar

    def decode(self, z):
        # Pass through decoder
        x_hat = self.decoder(z)

        # Reshape output tensor
        x_hat = x_hat.view(x_hat.size(0), 1, 28, 28)

        return x_hat

    def forward(self, x):
        # Pass through encoder and decoder
        z, mu, logvar = self.encode(x)
        x_hat = self.decode(z)

        return x_hat, mu, logvar

    def interpolate_mu(self, mu1, mu2, steps=10):
        alpha = torch.linspace(0, 1, steps, device=mu1.device)
        interpolations = []
        for a in alpha:
            interpolation = mu1 * (1 - a) + mu2 * a
            interpolations.append(interpolation)
        return torch.stack(interpolations)

def visualize_inter_class_interpolation(self, num_pairs=3, steps=10):
  
        # Select random pairs of images from the training set
        data = datasets.MNIST(root="./data", train=True, download=True, transform=transforms.ToTensor())
        pairs = []
        for i in range(num_pairs):
            while True:
                idx1, idx2 = np.random.randint(len(data), size=2)
                if data.targets[idx1] != data.targets[idx2]:
                    pairs.append((data[idx1][0], data[idx2][0]))
                    break

        # Encode each pair of images and take mean vectors
        mean_vectors = []
        for x1, x2 in pairs:
            z1, mu1, _ = self.encode(x1.unsqueeze(0))
            z2, mu2, _ = self.encode(x2.unsqueeze(0))
            mean_vectors.append((mu1, mu2))

        # Interpolate between mean vectors
        interpolations = []
        for mu1, mu2 in mean_vectors:
            z_interpolations = self.interpolate_mu(mu1, mu2, steps=steps)
            interpolations.append(z_interpolations)
            # Generate interpolated images and plot distributions
        fig, axs = plt.subplots(nrows=num_pairs, ncols=steps+2, figsize=(steps+2, num_pairs))
        for i, zs in enumerate(interpolations):
            x1, x2 = pairs[i]
            axs[i][0].imshow(x1.squeeze().detach().numpy(), cmap='gray')
            axs[i][0].axis('off')
            axs[i][steps+1].imshow(x2.squeeze().detach().numpy(), cmap='gray')
            axs[i][steps+1].axis('off')
        for j, z in enumerate(zs):
            x_hat = self.decode(z.unsqueeze(0)).squeeze().detach().numpy()
            axs[i][j+1].imshow(x_hat, cmap='gray')
            axs[i][j+1].axis('off')

            plt.tight_layout()
            plt.show()


        # Generate interpolated images and plot distributions
        plt.figure(figsize=(steps * 2, num_pairs * 2))
        for i, (x1, x2) in enumerate(pairs):
            for j, z in enumerate(interpolations[i]):
                with torch.no_grad():
                    x_hat = self.decode(z.unsqueeze(0))
                x_hat = x_hat.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()
                ax = plt.subplot(num_pairs, steps, i * steps + j + 1)
                ax.imshow(x_hat)
                ax.set_xticks([])
                ax.set_yticks([])
                if j == 0:
                    ax.set_ylabel(f"Pair {i + 1}", fontsize=14)
                if i == 0:
                    ax.set_title(f"Step {j + 1}", fontsize=14)
        plt.subplots_adjust(wspace=0, hspace=0)
        plt.show()

def visualize_inter_class_interpolation(self, num_pairs=3, steps=10):
        # Select random pairs of images from the training set
        data = datasets.MNIST(root="./data", train=True, download=True, transform=transforms.ToTensor())
        pairs = []
        for i in range(num_pairs):
            while True:
                idx1, idx2 = np.random.randint(len(data), size=2)
                if data.targets[idx1] != data.targets[idx2]:
                    pairs.append((data[idx1][0], data[idx2][0]))
                    break

        # Encode each pair of images and take mean vectors
        mean_vectors = []
        for x1, x2 in pairs:
            z1, mu1, _ = self.encode(x1.unsqueeze(0))
            z2, mu2, _ = self.encode(x2.unsqueeze(0))
            mean_vectors.append((mu1, mu2))

        # Interpolate between mean vectors
        interpolations = []
        for mu1, mu2 in mean_vectors:
            z_interpolations = self.interpolate_mu(mu1, mu2, steps=steps)
            interpolations.append(z_interpolations)

        # Generate interpolated images and plot distributions
        fig, axes = plt
                # Plot images and distributions
        plt.figure(figsize=(steps, num_pairs * 2))
        for i in range(num_pairs):
            for j in range(steps):
                # Generate interpolated image
                x_hat = self.decode(interpolations[i][j].unsqueeze(0))
                img = x_hat.squeeze().detach().numpy()

                # Plot image
                ax = plt.subplot(num_pairs, steps, i * steps + j + 1)
                ax.imshow(img, cmap="gray")
                ax.axis("off")

            # Plot distributions
            plt.subplot(num_pairs, steps, i * steps + 1)
            plt.title(f"Class {data.targets[pairs[i][0]]}")
            plt.subplot(num_pairs, steps, i * steps + steps)
            plt.title(f"Class {data.targets[pairs[i][1]]}")
            for mu1, mu2 in mean_vectors:
                plt.plot([mu1[0], mu2[0]], [mu1[1], mu2[1]], color="b")

        plt.tight_layout()
        plt.show()

def visualize_inter_class_interpolation(self, num_pairs=3, steps=10):
    # Select random pairs of images from the training set
    data = datasets.MNIST(root="./data", train=True, download=True, transform=transforms.ToTensor())
    pairs = []
    for i in range(num_pairs):
        while True:
            idx1, idx2 = np.random.randint(len(data), size=2)
            if data.targets[idx1] != data.targets[idx2]:
                pairs.append((data[idx1][0], data[idx2][0]))
                break

    # Encode each pair of images and take mean vectors
    mean_vectors = []
    for x1, x2 in pairs:
        z1, mu1, _ = self.encode(x1.unsqueeze(0))
        z2, mu2, _ = self.encode(x2.unsqueeze(0))
        mean_vectors.append((mu1, mu2))

    # Interpolate between mean vectors
    interpolations = []
    for mu1, mu2 in mean_vectors:
        z_interpolations = self.interpolate_mu(mu1, mu2, steps=steps)
        interpolations.append(z_interpolations)

    # Generate interpolated images and plot distributions
    plt.figure(figsize=(15, 5*num_pairs))
    for i, (x1, x2) in enumerate(pairs):
        z_int = interpolations[i]
        x_int = self.decode(z_int)
        x_grid = make_grid(torch.cat([x1.unsqueeze(0), x_int, x2.unsqueeze(0)], dim=0), nrow=steps+2)
        plt.subplot(num_pairs, 1, i+1)
        plt.imshow(x_grid.permute(1, 2, 0))
        plt.axis('off')
    plt.tight_layout()
    plt.show()
